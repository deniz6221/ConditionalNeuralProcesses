{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import importlib\n",
    "import homework4\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "importlib.reload(homework4)\n",
    "\n",
    "CNP = homework4.CNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(traj):   \n",
    "    random_rows = traj[np.random.choice(traj.shape[0], size=4, replace=False)]\n",
    "    \n",
    "    random_rows = np.array(random_rows)\n",
    "    \n",
    "    tensor_1 = torch.tensor([random_rows[:3]], dtype=torch.float32) \n",
    "    target_x = np.concatenate((random_rows[3][:2], [random_rows[3][4]]))\n",
    "    tensor_2 = torch.tensor([[target_x]], dtype=torch.float32) \n",
    "    tensor_3 = torch.tensor([[random_rows[3][2:4]]], dtype=torch.float32) \n",
    "    \n",
    "    return tensor_1, tensor_2, tensor_3\n",
    "\n",
    "def train():\n",
    "    d_x = 3\n",
    "    d_y = 2\n",
    "    model = CNP([d_x,d_y], 128, 3)\n",
    "    model.train()\n",
    "    training_data = np.load(\"states.npy\")\n",
    "    traj_count = len(training_data)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    loss_lst = []\n",
    "    for i in range(1_000_000):\n",
    "        traj = training_data[np.random.randint(traj_count)]\n",
    "        traj = torch.tensor(traj, dtype=torch.float32)\n",
    "        samples, target_x, target_y = generate_samples(traj)\n",
    "        loss = model.nll_loss(samples,target_x, target_y)\n",
    "        loss_lst.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"Epoch {i} Loss: {loss.item()}\")\n",
    "\n",
    "    return loss_lst, model    \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 1.1970949172973633\n",
      "Epoch 1000 Loss: -1.3166563510894775\n",
      "Epoch 2000 Loss: -1.3478864431381226\n",
      "Epoch 3000 Loss: -1.3492813110351562\n",
      "Epoch 4000 Loss: -1.382008671760559\n",
      "Epoch 5000 Loss: -1.3101987838745117\n",
      "Epoch 6000 Loss: -1.357648491859436\n",
      "Epoch 7000 Loss: -1.3714462518692017\n",
      "Epoch 8000 Loss: -1.2652702331542969\n",
      "Epoch 9000 Loss: -1.3643547296524048\n",
      "Epoch 10000 Loss: -1.3774372339248657\n",
      "Epoch 11000 Loss: -1.3141387701034546\n",
      "Epoch 12000 Loss: -1.3771777153015137\n",
      "Epoch 13000 Loss: -1.3810648918151855\n",
      "Epoch 14000 Loss: -1.3705166578292847\n",
      "Epoch 15000 Loss: -1.374531626701355\n",
      "Epoch 16000 Loss: -1.373558759689331\n",
      "Epoch 17000 Loss: -1.3812880516052246\n",
      "Epoch 18000 Loss: -1.3771785497665405\n",
      "Epoch 19000 Loss: -1.3766765594482422\n",
      "Epoch 20000 Loss: -1.3822733163833618\n",
      "Epoch 21000 Loss: -1.3796900510787964\n",
      "Epoch 22000 Loss: -1.2547647953033447\n",
      "Epoch 23000 Loss: -1.3798322677612305\n",
      "Epoch 24000 Loss: -1.3820492029190063\n",
      "Epoch 25000 Loss: -1.3834145069122314\n",
      "Epoch 26000 Loss: -1.3815912008285522\n",
      "Epoch 27000 Loss: -1.3784539699554443\n",
      "Epoch 28000 Loss: -1.373734951019287\n",
      "Epoch 29000 Loss: -1.3654098510742188\n",
      "Epoch 30000 Loss: -1.3631263971328735\n",
      "Epoch 31000 Loss: -1.3819243907928467\n",
      "Epoch 32000 Loss: -1.3769487142562866\n",
      "Epoch 33000 Loss: -1.3826662302017212\n",
      "Epoch 34000 Loss: -1.374192237854004\n",
      "Epoch 35000 Loss: -1.3802523612976074\n",
      "Epoch 36000 Loss: -1.378886103630066\n",
      "Epoch 37000 Loss: -1.310744047164917\n",
      "Epoch 38000 Loss: -1.383642315864563\n",
      "Epoch 39000 Loss: -1.3827418088912964\n",
      "Epoch 40000 Loss: -1.304187536239624\n",
      "Epoch 41000 Loss: -1.3800468444824219\n",
      "Epoch 42000 Loss: -0.5420979857444763\n",
      "Epoch 43000 Loss: -1.3734022378921509\n",
      "Epoch 44000 Loss: -1.3832625150680542\n",
      "Epoch 45000 Loss: -1.379502773284912\n",
      "Epoch 46000 Loss: -1.3815633058547974\n",
      "Epoch 47000 Loss: -1.3614568710327148\n",
      "Epoch 48000 Loss: -1.376136302947998\n",
      "Epoch 49000 Loss: -1.3832931518554688\n",
      "Epoch 50000 Loss: -1.3773205280303955\n",
      "Epoch 51000 Loss: -1.383467197418213\n",
      "Epoch 52000 Loss: -1.382088541984558\n",
      "Epoch 53000 Loss: -1.3828504085540771\n",
      "Epoch 54000 Loss: -1.3742189407348633\n",
      "Epoch 55000 Loss: -1.383346676826477\n",
      "Epoch 56000 Loss: -1.381988763809204\n",
      "Epoch 57000 Loss: -1.3833155632019043\n",
      "Epoch 58000 Loss: -1.3773037195205688\n",
      "Epoch 59000 Loss: -1.3817051649093628\n",
      "Epoch 60000 Loss: -1.3757593631744385\n",
      "Epoch 61000 Loss: -1.3763651847839355\n",
      "Epoch 62000 Loss: -1.3762816190719604\n",
      "Epoch 63000 Loss: -1.382614254951477\n",
      "Epoch 64000 Loss: -1.3801168203353882\n",
      "Epoch 65000 Loss: -1.3833184242248535\n",
      "Epoch 66000 Loss: -1.3834617137908936\n",
      "Epoch 67000 Loss: -1.3826619386672974\n",
      "Epoch 68000 Loss: -1.3789019584655762\n",
      "Epoch 69000 Loss: -1.3760241270065308\n",
      "Epoch 70000 Loss: -1.3714954853057861\n",
      "Epoch 71000 Loss: -1.3835992813110352\n",
      "Epoch 72000 Loss: -1.382624626159668\n",
      "Epoch 73000 Loss: -1.3833589553833008\n",
      "Epoch 74000 Loss: -1.353939175605774\n",
      "Epoch 75000 Loss: -1.3835604190826416\n",
      "Epoch 76000 Loss: -1.3826903104782104\n",
      "Epoch 77000 Loss: -1.3833279609680176\n",
      "Epoch 78000 Loss: -1.3806895017623901\n",
      "Epoch 79000 Loss: -1.3818265199661255\n",
      "Epoch 80000 Loss: -1.3804904222488403\n",
      "Epoch 81000 Loss: -1.3825026750564575\n",
      "Epoch 82000 Loss: -1.3801261186599731\n",
      "Epoch 83000 Loss: -1.3835798501968384\n",
      "Epoch 84000 Loss: -1.3831570148468018\n",
      "Epoch 85000 Loss: -1.3797794580459595\n",
      "Epoch 86000 Loss: -1.381369709968567\n",
      "Epoch 87000 Loss: -1.3829429149627686\n",
      "Epoch 88000 Loss: -1.3835431337356567\n",
      "Epoch 89000 Loss: -1.3488123416900635\n",
      "Epoch 90000 Loss: -1.3799487352371216\n",
      "Epoch 91000 Loss: -1.382549524307251\n",
      "Epoch 92000 Loss: -1.2945159673690796\n",
      "Epoch 93000 Loss: -1.2212923765182495\n",
      "Epoch 94000 Loss: -1.3353910446166992\n",
      "Epoch 95000 Loss: -1.3828641176223755\n",
      "Epoch 96000 Loss: -1.3832952976226807\n",
      "Epoch 97000 Loss: -1.3834717273712158\n",
      "Epoch 98000 Loss: -1.3831186294555664\n",
      "Epoch 99000 Loss: -1.379476547241211\n"
     ]
    }
   ],
   "source": [
    "loss_lst, model = train() \n",
    "model.eval()\n",
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
